{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AminoAcidLM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "y1lA1tMTiyNw"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S11CAvUpf85P"
      },
      "source": [
        "# Pytorch Amin Acid Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EzLqPjqf6n_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IqrdfcCgPhm"
      },
      "source": [
        "if torch.cuda.is_available():  \n",
        "  dev = \"cuda:0\" \n",
        "else:  \n",
        "  dev = \"cpu\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HQArlylGRmTL",
        "outputId": "f9a9ba2e-ff26-4e84-b13a-949406843f3e"
      },
      "source": [
        "dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG_svVhvhRH0",
        "outputId": "69321871-f700-4336-ba8d-6fc014146fb3"
      },
      "source": [
        "torch.manual_seed(42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3d3a315810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzMtjrTjjFG1"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Rhajs1ZZjH-D",
        "outputId": "4ee53248-817f-41b7-9732-c0eea4f4a5b8"
      },
      "source": [
        "data_file = Path('/content/LM_data_2021-03-11.csv')\n",
        "df = pd.read_csv(data_file, sep=';')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Entry</th>\n",
              "      <th>Entry name</th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P68307</td>\n",
              "      <td>NU3M_BALMU</td>\n",
              "      <td>MNLLLTLLTNTTLALLLVFIAFWLPQLNVYAEKTSPYECGFDPMGS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P0CY61</td>\n",
              "      <td>O162_CONBU</td>\n",
              "      <td>MKLTCVLIIAVLFLTAITADDSRDKQVYRAVGLIDKMRRIRASEGC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q0VIL3</td>\n",
              "      <td>OTOMP_DANRE</td>\n",
              "      <td>MDLPGGHLAVVLFLFVLVSMSTENNIIRWCTVSDAEDQKCLDLAGN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A1W9I4</td>\n",
              "      <td>NUSB_ACISJ</td>\n",
              "      <td>MTDSTHPTPSARPPRQPRTGTTGTGARKAGSKSGRSRAREFALQAL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q8DBX0</td>\n",
              "      <td>OMPU_VIBVU</td>\n",
              "      <td>MKKTLIALSVSAAAVATGVNAAELYNQDGTSLDMGGRAEARLSMKD...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Entry   Entry name                                           Sequence\n",
              "0  P68307   NU3M_BALMU  MNLLLTLLTNTTLALLLVFIAFWLPQLNVYAEKTSPYECGFDPMGS...\n",
              "1  P0CY61   O162_CONBU  MKLTCVLIIAVLFLTAITADDSRDKQVYRAVGLIDKMRRIRASEGC...\n",
              "2  Q0VIL3  OTOMP_DANRE  MDLPGGHLAVVLFLFVLVSMSTENNIIRWCTVSDAEDQKCLDLAGN...\n",
              "3  A1W9I4   NUSB_ACISJ  MTDSTHPTPSARPPRQPRTGTTGTGARKAGSKSGRSRAREFALQAL...\n",
              "4  Q8DBX0   OMPU_VIBVU  MKKTLIALSVSAAAVATGVNAAELYNQDGTSLDMGGRAEARLSMKD..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "tBUVBC9foiCs",
        "outputId": "1f353e73-345f-47e5-aa39-0e0c5096709f"
      },
      "source": [
        "df.drop(['Entry', 'Entry name'], axis = 1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MNLLLTLLTNTTLALLLVFIAFWLPQLNVYAEKTSPYECGFDPMGS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MKLTCVLIIAVLFLTAITADDSRDKQVYRAVGLIDKMRRIRASEGC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MDLPGGHLAVVLFLFVLVSMSTENNIIRWCTVSDAEDQKCLDLAGN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MTDSTHPTPSARPPRQPRTGTTGTGARKAGSKSGRSRAREFALQAL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MKKTLIALSVSAAAVATGVNAAELYNQDGTSLDMGGRAEARLSMKD...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sequence\n",
              "0  MNLLLTLLTNTTLALLLVFIAFWLPQLNVYAEKTSPYECGFDPMGS...\n",
              "1  MKLTCVLIIAVLFLTAITADDSRDKQVYRAVGLIDKMRRIRASEGC...\n",
              "2  MDLPGGHLAVVLFLFVLVSMSTENNIIRWCTVSDAEDQKCLDLAGN...\n",
              "3  MTDSTHPTPSARPPRQPRTGTTGTGARKAGSKSGRSRAREFALQAL...\n",
              "4  MKKTLIALSVSAAAVATGVNAAELYNQDGTSLDMGGRAEARLSMKD..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny7DQRNqg3CE"
      },
      "source": [
        "## Tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQGGZRg_hJsn"
      },
      "source": [
        "# Set-up numpy generator for random numbers\n",
        "random_number_generator = np.random.default_rng(seed=42)\n",
        "KMER_SIZE = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgddkaKhhP8D"
      },
      "source": [
        "# Tokenize the protein sequence (or any sequence) in kmers.\n",
        "def tokenize(protein_seqs, kmer_sz):\n",
        "    kmers = set()\n",
        "    # Loop over protein sequences\n",
        "    for protein_seq in protein_seqs:\n",
        "        # Loop over the whole sequence\n",
        "        for i in range(len(protein_seq) - (kmer_sz - 1)):\n",
        "            # Add kmers to the set, thus only unique kmers will remain\n",
        "            kmers.add(protein_seq[i: i + kmer_sz])\n",
        "            \n",
        "    # Map kmers for one hot-encoding\n",
        "    kmer_to_id = dict()\n",
        "    id_to_kmer = dict()\n",
        "    \n",
        "    for ind, kmer in enumerate(kmers):\n",
        "        kmer_to_id[kmer] = ind\n",
        "        id_to_kmer[ind] = kmer\n",
        "        \n",
        "    vocab_sz = len(kmers)\n",
        "    \n",
        "    assert vocab_sz == len(kmer_to_id.keys())\n",
        "    \n",
        "    # Tokenize the protein sequence to integers\n",
        "    tokenized = []\n",
        "    for protein_seq in protein_seqs:\n",
        "        sequence = []\n",
        "        for i in  range(len(protein_seq) - (kmer_sz -1)):\n",
        "            # Convert kmer to integer\n",
        "            kmer = protein_seq[i: i + kmer_sz]\n",
        "            sequence.append(kmer_to_id[kmer])\n",
        "            \n",
        "        tokenized.append(sequence)\n",
        "            \n",
        "    \n",
        "    return tokenized, vocab_sz, kmer_to_id, id_to_kmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6RSsp1yhoZk"
      },
      "source": [
        "# Tokenize the protein sequence\n",
        "tokenized_seqs, vocab_sz, kmer_to_id, id_to_kmer = tokenize(df['Sequence'], KMER_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDknJFgyhsGe",
        "outputId": "f4a3846e-baa8-435c-b338-8d5897a8a0cf"
      },
      "source": [
        "vocab_sz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0FGm4cBhtvA",
        "outputId": "3b9587f2-ed36-45b2-9288-96ddeb2613db"
      },
      "source": [
        "tokenized_seqs[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6613, 1030, 1596, 2497, 7681, 6098, 2497, 2622, 614, 6238]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UQoexMBhweb"
      },
      "source": [
        "data = []\n",
        "for seq in tokenized_seqs:\n",
        "    for kmer in seq:\n",
        "        data.append(kmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bFDTL1rh0so"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KThomvMoh3YI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "de8cfc5d-d161-47af-e9e9-e715361994c5"
      },
      "source": [
        "class AminoLMDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        self.data = torch.Tensor(data)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "            \n",
        "        xs = torch.LongTensor(data[idx: idx + seq_len])\n",
        "        targets = data[idx + 1: idx + seq_len + 1]\n",
        "\n",
        "        ys = []\n",
        "\n",
        "        for target in targets:\n",
        "          y = torch.tensor(target)\n",
        "          ys.append(y)\n",
        "\n",
        "        ys = torch.stack(ys)\n",
        "\n",
        "        ys = ys.to(dev)\n",
        "        xs = xs.to(dev) \n",
        "    \n",
        "        return xs, ys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-709929282a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAminoLMDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvWU-tRBim7d"
      },
      "source": [
        "## Building the LM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql5EKTgciqZ5"
      },
      "source": [
        "# Hyperparameters\n",
        "emb_dim = 400 # Embeddding dimension\n",
        "hid_sz = 1150 # Hidden size\n",
        "num_layers = 3 # Number of LSTM layers stacked together\n",
        "seq_len = num_layers\n",
        "\n",
        "# Dropout parameters\n",
        "\n",
        "embed_p = 0.1 # Dropout probability on the embedding\n",
        "hidden_p = 0.3 # Dropout probability on hidden-to-hidden weight matrices\n",
        "input_p = 0.3 # Dropout probablity on the LSTM input between LSTMS\n",
        "\n",
        "# This one still has to be implemented\n",
        "#weight_p = 0.5 # Dropout probability on LSTM-to-LSTM weight matrices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9dLYlNPi53-"
      },
      "source": [
        "class AWD_LSTM(torch.nn.Module):\n",
        "    def __init__(self, num_layers, vocab_sz, emb_dim, hid_sz, hidden_p, embed_p, input_p):\n",
        "        super(AWD_LSTM, self).__init__()\n",
        "        \n",
        "        self.encoder = torch.nn.Embedding(vocab_sz, emb_dim)\n",
        "        self.emb_drop = torch.nn.Dropout(p=embed_p)\n",
        "\n",
        "        self.lstms = []\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            self.lstms.append(nn.LSTM(input_size=emb_dim, hidden_size=hid_sz, num_layers=1))\n",
        "\n",
        "        self.lstms = nn.ModuleList(self.lstms)\n",
        "\n",
        "        self.decoder = torch.nn.Linear(hid_sz, vocab_sz)\n",
        "        \n",
        "        self.num_layers = num_layers\n",
        "        self.vocab_sz = vocab_sz\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hid_sz = hid_sz\n",
        "        self.hidden_p = hidden_p\n",
        "        self.embed_p = embed_p\n",
        "        self.input_p = input_p\n",
        "        self.batch_sz = 1\n",
        "        \n",
        "        self.reset_hidden()\n",
        "                \n",
        "    def forward(self, xs):\n",
        "        \"\"\"Forward pass AWD-LSTM\"\"\" \n",
        "\n",
        "        ys = []\n",
        "\n",
        "\n",
        "        self.reset_hidden()\n",
        "        \n",
        "        hiddens = (self.hidden_state, self.cell_state)\n",
        "\n",
        "        for i, lstm in enumerate(self.lstms):\n",
        "          embed = self.encoder(xs[i])\n",
        "          output, hiddens = lstm(embed.view(1, 1, -1), hiddens)  \n",
        "            \n",
        "          y = self.decoder(output)\n",
        "\n",
        "          # Outputs moeten squeezen om de loss toe te kunnen passen, maar moet nog even kijken of de juiste waardes dan wel worden mee genomen\n",
        "\n",
        "          ys.append(y.squeeze(0).squeeze(0))\n",
        "\n",
        "        y = torch.stack(ys, dim=0)\n",
        "        \n",
        "        return y\n",
        "    \n",
        "    def reset_hidden(self):\n",
        "        self.hidden_state = torch.zeros((1, self.batch_sz, self.hid_sz)).to(dev)\n",
        "        self.cell_state = torch.zeros((1, self.batch_sz, self.hid_sz)).to(dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_KF4fBAjtyL",
        "outputId": "1383713d-ce29-440f-92ae-d7d583dc9c4f"
      },
      "source": [
        "model = AWD_LSTM(num_layers, vocab_sz, emb_dim, hid_sz, hidden_p, embed_p, input_p)\n",
        "model = model.to(dev)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AWD_LSTM(\n",
              "  (encoder): Embedding(9317, 400)\n",
              "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
              "  (lstms): ModuleList(\n",
              "    (0): LSTM(400, 1150)\n",
              "    (1): LSTM(400, 1150)\n",
              "    (2): LSTM(400, 1150)\n",
              "  )\n",
              "  (decoder): Linear(in_features=1150, out_features=9317, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8hx9Yj2jwvg"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H4vVpkTj5Np"
      },
      "source": [
        "training_set = AminoLMDataset(data, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnOwAHn_j8Wb"
      },
      "source": [
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEnPLliaj_Do",
        "outputId": "2c3aa7c6-7de2-4023-f366-0f694947d75e"
      },
      "source": [
        "total_train_len = len(training_loader)\n",
        "total_train_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58461351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbsURPMIqr9X",
        "outputId": "3904e4f0-cd37-442e-82b1-8e9ff160d8fb"
      },
      "source": [
        "# Test for the real work\n",
        "for i, entry in enumerate(training_loader, 0):\n",
        "    xs, ys = entry[0], entry[1]\n",
        "\n",
        "    outputs = model(xs.squeeze(0))\n",
        "\n",
        "    print(outputs.shape)\n",
        "    print(ys.shape)\n",
        "\n",
        "    loss = criterion(outputs, ys.squeeze(0))\n",
        "    print(loss)\n",
        "    \n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 9317])\n",
            "torch.Size([1, 3])\n",
            "tensor(9.1061, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rljV58FkC-Y"
      },
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "epochs = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivU0Dva6kJW-"
      },
      "source": [
        "# Costfunction and optimize algorithm\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "29idEGfVkMH_",
        "outputId": "1f7d18ea-eeda-42ef-c116-ba7311794a09"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    \n",
        "    model.reset_hidden()\n",
        "    \n",
        "    # Initialize loss at 0\n",
        "    epoch_loss = 0.0\n",
        "    \n",
        "    print(f'Epoch: {str(epoch + 1)}')\n",
        "    \n",
        "    for i, entry in enumerate(training_loader, 0):\n",
        "        \n",
        "        \n",
        "        model.zero_grad()\n",
        "        \n",
        "        xs, ys = entry[0], entry[1]\n",
        "        \n",
        "        outputs = model(xs.squeeze(0))\n",
        "        loss = criterion(outputs, ys.squeeze(0))\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "        if i % 1e4 == 0:\n",
        "            perc = i / total_train_len * 100\n",
        "            print(f'Percent: {str(perc)}')\n",
        "            print(f'Loss: {str(loss.item())}')\n",
        "    \n",
        "    loss_history.append(epoch_loss)\n",
        "    \n",
        "    print(f'Epoch {str(epoch + 1)} Train loss: {str(epoch_loss)}.')\n",
        "          \n",
        "print('Finished training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Percent: 0.0\n",
            "Loss: 8.85924243927002\n",
            "Percent: 0.01710531800744735\n",
            "Loss: 8.926836967468262\n",
            "Percent: 0.0342106360148947\n",
            "Loss: 9.091572761535645\n",
            "Percent: 0.05131595402234205\n",
            "Loss: 8.935885429382324\n",
            "Percent: 0.0684212720297894\n",
            "Loss: 9.17000961303711\n",
            "Percent: 0.08552659003723674\n",
            "Loss: 8.62395191192627\n",
            "Percent: 0.1026319080446841\n",
            "Loss: 8.910038948059082\n",
            "Percent: 0.11973722605213143\n",
            "Loss: 8.816948890686035\n",
            "Percent: 0.1368425440595788\n",
            "Loss: 7.374332427978516\n",
            "Percent: 0.15394786206702613\n",
            "Loss: 9.096847534179688\n",
            "Percent: 0.17105318007447348\n",
            "Loss: 8.81326961517334\n",
            "Percent: 0.1881584980819208\n",
            "Loss: 7.947908401489258\n",
            "Percent: 0.2052638160893682\n",
            "Loss: 8.776854515075684\n",
            "Percent: 0.2223691340968155\n",
            "Loss: 8.7290678024292\n",
            "Percent: 0.23947445210426285\n",
            "Loss: 9.786087989807129\n",
            "Percent: 0.25657977011171024\n",
            "Loss: 8.355191230773926\n",
            "Percent: 0.2736850881191576\n",
            "Loss: 8.411930084228516\n",
            "Percent: 0.2907904061266049\n",
            "Loss: 7.8287811279296875\n",
            "Percent: 0.30789572413405225\n",
            "Loss: 7.402301788330078\n",
            "Percent: 0.3250010421414996\n",
            "Loss: 6.459616184234619\n",
            "Percent: 0.34210636014894696\n",
            "Loss: 6.397752285003662\n",
            "Percent: 0.3592116781563943\n",
            "Loss: 7.634504795074463\n",
            "Percent: 0.3763169961638416\n",
            "Loss: 8.418366432189941\n",
            "Percent: 0.39342231417128903\n",
            "Loss: 7.8364949226379395\n",
            "Percent: 0.4105276321787364\n",
            "Loss: 7.907639026641846\n",
            "Percent: 0.42763295018618364\n",
            "Loss: 4.440743446350098\n",
            "Percent: 0.444738268193631\n",
            "Loss: 7.762857913970947\n",
            "Percent: 0.46184358620107835\n",
            "Loss: 7.775102138519287\n",
            "Percent: 0.4789489042085257\n",
            "Loss: 6.442179203033447\n",
            "Percent: 0.49605422221597306\n",
            "Loss: 6.539733409881592\n",
            "Percent: 0.5131595402234205\n",
            "Loss: 0.7579562067985535\n",
            "Percent: 0.5302648582308678\n",
            "Loss: 3.0201120376586914\n",
            "Percent: 0.5473701762383152\n",
            "Loss: 3.231069564819336\n",
            "Percent: 0.5644754942457625\n",
            "Loss: 7.101423740386963\n",
            "Percent: 0.5815808122532098\n",
            "Loss: 4.101141929626465\n",
            "Percent: 0.5986861302606571\n",
            "Loss: 6.351629257202148\n",
            "Percent: 0.6157914482681045\n",
            "Loss: 5.138593673706055\n",
            "Percent: 0.6328967662755518\n",
            "Loss: 7.685041904449463\n",
            "Percent: 0.6500020842829992\n",
            "Loss: 4.480146408081055\n",
            "Percent: 0.6671074022904465\n",
            "Loss: 9.014039993286133\n",
            "Percent: 0.6842127202978939\n",
            "Loss: 5.26225471496582\n",
            "Percent: 0.7013180383053412\n",
            "Loss: 4.474151611328125\n",
            "Percent: 0.7184233563127886\n",
            "Loss: 1.0476545095443726\n",
            "Percent: 0.7355286743202359\n",
            "Loss: 0.4257868528366089\n",
            "Percent: 0.7526339923276832\n",
            "Loss: 2.03759503364563\n",
            "Percent: 0.7697393103351307\n",
            "Loss: 5.56923246383667\n",
            "Percent: 0.7868446283425781\n",
            "Loss: 3.434954881668091\n",
            "Percent: 0.8039499463500254\n",
            "Loss: 2.284954786300659\n",
            "Percent: 0.8210552643574728\n",
            "Loss: 3.4759533405303955\n",
            "Percent: 0.83816058236492\n",
            "Loss: 6.556528568267822\n",
            "Percent: 0.8552659003723673\n",
            "Loss: 3.8162572383880615\n",
            "Percent: 0.8723712183798147\n",
            "Loss: 4.460156440734863\n",
            "Percent: 0.889476536387262\n",
            "Loss: 3.327962636947632\n",
            "Percent: 0.9065818543947094\n",
            "Loss: 3.1047849655151367\n",
            "Percent: 0.9236871724021567\n",
            "Loss: 3.6285860538482666\n",
            "Percent: 0.9407924904096041\n",
            "Loss: 3.520970344543457\n",
            "Percent: 0.9578978084170514\n",
            "Loss: 1.8408094644546509\n",
            "Percent: 0.9750031264244988\n",
            "Loss: 1.4220722913742065\n",
            "Percent: 0.9921084444319461\n",
            "Loss: 5.678014278411865\n",
            "Percent: 1.0092137624393935\n",
            "Loss: 0.7210485339164734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-672ab3615a7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m'momentum_buffer'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                         \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoxUmcl1q4ep"
      },
      "source": [
        "## Save Model for Training Later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_fi4v03syH_",
        "outputId": "2adf5969-0568-4d89-fb15-9df9cb35c6cf"
      },
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "drive.mount('content/', force_remount=True)\n",
        "base = Path('/content/content/My Drive/')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at content/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6fqe1X8s7fD",
        "outputId": "559edaa6-f318-409d-f6ed-d07fe64409e4"
      },
      "source": [
        "filename = '1_percent_AA_LM.pt'\n",
        "file_dir = Path('/content/content/MyDrive/' + filename)\n",
        "file_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/content/MyDrive/1_percent_AA_LM.pt')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsq47uB5tU04"
      },
      "source": [
        "torch.save(model, file_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2olAPq3h4PX"
      },
      "source": [
        "## Load Model for Further Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB50rANmh9F5",
        "outputId": "64559829-c29a-40ec-9682-8e8274d5fca9"
      },
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "drive.mount('content/', force_remount=True)\n",
        "base = Path('/content/content/My Drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at content/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8P3I4zMiJkt",
        "outputId": "4426a636-25b7-4270-8f2e-8e8391f958cc"
      },
      "source": [
        "model_path = Path('/content/content/MyDrive/1_percent_AA_LM.pt')\n",
        "model = torch.load(model_path)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AWD_LSTM(\n",
              "  (encoder): Embedding(9317, 400)\n",
              "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
              "  (lstms): ModuleList(\n",
              "    (0): LSTM(400, 1150)\n",
              "    (1): LSTM(400, 1150)\n",
              "    (2): LSTM(400, 1150)\n",
              "  )\n",
              "  (decoder): Linear(in_features=1150, out_features=9317, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQY05bXyjFry"
      },
      "source": [
        "### Train Further with Data of which the location is known"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "gFNPH-PHjLum",
        "outputId": "28fa9f8e-b254-44e7-e0a1-0c8ecb0cba42"
      },
      "source": [
        "data_file = Path('/content/protein_data_2021-02-07.csv')\n",
        "df = pd.read_csv(data_file, sep=';')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Entry</th>\n",
              "      <th>Entry name</th>\n",
              "      <th>Protein names</th>\n",
              "      <th>Gene names</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Subcellular location [CC]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>O95825</td>\n",
              "      <td>QORL1_HUMAN</td>\n",
              "      <td>Quinone oxidoreductase-like protein 1 (EC 1.-....</td>\n",
              "      <td>CRYZL1 4P11</td>\n",
              "      <td>MKGLYFQQSSTDEEITFVFQEKEDLPVTEDNFVKLQVKACALSQIN...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Q9Y2J0</td>\n",
              "      <td>RP3A_HUMAN</td>\n",
              "      <td>Rabphilin-3A (Exophilin-1)</td>\n",
              "      <td>RPH3A KIAA0985</td>\n",
              "      <td>MTDTVFSNSSNRWMYPSDRPLQSNDKEQLQAGWSVHPGGQPDRQRK...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cytoplasmic vesicle, sec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Q13905</td>\n",
              "      <td>RPGF1_HUMAN</td>\n",
              "      <td>Rap guanine nucleotide exchange factor 1 (CRK ...</td>\n",
              "      <td>RAPGEF1 GRF2</td>\n",
              "      <td>MDTDSQRSHLSSFTMKLMDKFHSPKIKRTPSKKGKPAEVSVKIPEK...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Early endosome {ECO:0000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Q5TD94</td>\n",
              "      <td>RSH4A_HUMAN</td>\n",
              "      <td>Radial spoke head protein 4 homolog A (Radial ...</td>\n",
              "      <td>RSPH4A RSHL3</td>\n",
              "      <td>MEDSTSPKQEKENQEELGETRRPWEGKTAASPQYSEPESSEPLEAK...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cytoplasm, cytoskeleton,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Q9HA92</td>\n",
              "      <td>RSAD1_HUMAN</td>\n",
              "      <td>Radical S-adenosyl methionine domain-containin...</td>\n",
              "      <td>RSAD1</td>\n",
              "      <td>MALPGARARGWAAAARAAQRRRRVENAGGSPSPEPAGRRAALYVHW...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Mitochondrion {ECO:00003...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                          Subcellular location [CC]\n",
              "0           0  ...                                                NaN\n",
              "1           1  ...  SUBCELLULAR LOCATION: Cytoplasmic vesicle, sec...\n",
              "2           2  ...  SUBCELLULAR LOCATION: Early endosome {ECO:0000...\n",
              "3           3  ...  SUBCELLULAR LOCATION: Cytoplasm, cytoskeleton,...\n",
              "4           4  ...  SUBCELLULAR LOCATION: Mitochondrion {ECO:00003...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "6QeDY33rjQmk",
        "outputId": "319ae203-805d-4089-c864-e0e792018644"
      },
      "source": [
        "df.drop(['Unnamed: 0', 'Entry', 'Entry name', 'Protein names', 'Gene names', 'Subcellular location [CC]'], axis = 1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MKGLYFQQSSTDEEITFVFQEKEDLPVTEDNFVKLQVKACALSQIN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MTDTVFSNSSNRWMYPSDRPLQSNDKEQLQAGWSVHPGGQPDRQRK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MDTDSQRSHLSSFTMKLMDKFHSPKIKRTPSKKGKPAEVSVKIPEK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MEDSTSPKQEKENQEELGETRRPWEGKTAASPQYSEPESSEPLEAK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MALPGARARGWAAAARAAQRRRRVENAGGSPSPEPAGRRAALYVHW...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sequence\n",
              "0  MKGLYFQQSSTDEEITFVFQEKEDLPVTEDNFVKLQVKACALSQIN...\n",
              "1  MTDTVFSNSSNRWMYPSDRPLQSNDKEQLQAGWSVHPGGQPDRQRK...\n",
              "2  MDTDSQRSHLSSFTMKLMDKFHSPKIKRTPSKKGKPAEVSVKIPEK...\n",
              "3  MEDSTSPKQEKENQEELGETRRPWEGKTAASPQYSEPESSEPLEAK...\n",
              "4  MALPGARARGWAAAARAAQRRRRVENAGGSPSPEPAGRRAALYVHW..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8Tv84KlmCSl",
        "outputId": "7d34b845-e404-4315-a1a4-f47a53860385"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50R74aizj93G"
      },
      "source": [
        "Deze data moet hetzelfde getokeniseerd worden als de hele corpus, daarom moet ik die kmer_to_id opslaan en die gebruiken."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgPJVIF8jl_1"
      },
      "source": [
        "# Tokenize the protein sequence to integers\n",
        "tokenized = []\n",
        "for i, protein_seq in enumerate(df['Sequence']):\n",
        "    sequence = []\n",
        "    for i in  range(len(protein_seq) - (KMER_SIZE -1)):\n",
        "        # Convert kmer to integer\n",
        "        kmer = protein_seq[i: i + KMER_SIZE]\n",
        "        \n",
        "        try:\n",
        "          sequence.append(kmer_to_id[kmer])\n",
        "        except:\n",
        "          # If the KMER is for some unknown reason not in the vocab then delete the row from the dataframe\n",
        "          df.drop(i, inplace=True)\n",
        "\n",
        "    tokenized.append(sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcg-95gmmNv1",
        "outputId": "69f8f137-88b8-434a-af27-ce26872b9d50"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlGSEoqFjoik",
        "outputId": "c7961425-0786-411a-e5e2-6be8f3e7a2fd"
      },
      "source": [
        "tokenized[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[157, 8770, 6108, 4111, 1747, 2328, 4276, 8642, 6792, 9194]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXiEy8vumVw4"
      },
      "source": [
        "data = []\n",
        "for seq in tokenized:\n",
        "    for kmer in seq:\n",
        "        data.append(kmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox6DmpAZmaD9"
      },
      "source": [
        "### Train with the new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iVIHGtEmeQI"
      },
      "source": [
        "training_set = AminoLMDataset(data, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enzAH5b1moUI"
      },
      "source": [
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRmnqTD3ms4O",
        "outputId": "4cc0a581-98b8-4202-9071-75ef294ec0c4"
      },
      "source": [
        "total_train_len = len(training_loader)\n",
        "total_train_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11323425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jWzBj-Bm1zj"
      },
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "epochs = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tK5cGZhm228"
      },
      "source": [
        "# Costfunction and optimize algorithm\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6yPlt-lhm7hi",
        "outputId": "16f899ae-98d4-4fbd-cc39-e151bc39a7b6"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    \n",
        "    model.reset_hidden()\n",
        "    \n",
        "    # Initialize loss at 0\n",
        "    epoch_loss = 0.0\n",
        "    \n",
        "    print(f'Epoch: {str(epoch + 1)}')\n",
        "    \n",
        "    for i, entry in enumerate(training_loader, 0):\n",
        "        \n",
        "        \n",
        "        model.zero_grad()\n",
        "        \n",
        "        xs, ys = entry[0], entry[1]\n",
        "        \n",
        "        outputs = model(xs.squeeze(0))\n",
        "        loss = criterion(outputs, ys.squeeze(0))\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "        if i % 1.5e4 == 0:\n",
        "            perc = i / total_train_len * 100\n",
        "            print(f'Percent: {str(perc)}')\n",
        "            print(f'Loss: {str(loss.item())}')\n",
        "    \n",
        "    loss_history.append(epoch_loss)\n",
        "    \n",
        "    print(f'Epoch {str(epoch + 1)} Train loss: {str(epoch_loss)}.')\n",
        "          \n",
        "print('Finished training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Percent: 0.0\n",
            "Loss: 11.375401496887207\n",
            "Percent: 0.13246875393266613\n",
            "Loss: 8.15804672241211\n",
            "Percent: 0.26493750786533227\n",
            "Loss: 9.12777328491211\n",
            "Percent: 0.3974062617979984\n",
            "Loss: 9.250300407409668\n",
            "Percent: 0.5298750157306645\n",
            "Loss: 9.036314964294434\n",
            "Percent: 0.6623437696633306\n",
            "Loss: 9.138776779174805\n",
            "Percent: 0.7948125235959967\n",
            "Loss: 5.583368301391602\n",
            "Percent: 0.927281277528663\n",
            "Loss: 4.445772171020508\n",
            "Percent: 1.059750031461329\n",
            "Loss: 8.011649131774902\n",
            "Percent: 1.1922187853939952\n",
            "Loss: 3.1863505840301514\n",
            "Percent: 1.3246875393266613\n",
            "Loss: 2.9561500549316406\n",
            "Percent: 1.4571562932593274\n",
            "Loss: 7.1134114265441895\n",
            "Percent: 1.5896250471919935\n",
            "Loss: 8.157109260559082\n",
            "Percent: 1.7220938011246596\n",
            "Loss: 6.495886325836182\n",
            "Percent: 1.854562555057326\n",
            "Loss: 2.9495487213134766\n",
            "Percent: 1.9870313089899923\n",
            "Loss: 7.4272003173828125\n",
            "Percent: 2.119500062922658\n",
            "Loss: 7.234080791473389\n",
            "Percent: 2.2519688168553245\n",
            "Loss: 3.666826009750366\n",
            "Percent: 2.3844375707879903\n",
            "Loss: 6.497460842132568\n",
            "Percent: 2.5169063247206567\n",
            "Loss: 6.002417087554932\n",
            "Percent: 2.6493750786533226\n",
            "Loss: 4.38109827041626\n",
            "Percent: 2.781843832585989\n",
            "Loss: 2.3284780979156494\n",
            "Percent: 2.9143125865186548\n",
            "Loss: 2.416309118270874\n",
            "Percent: 3.046781340451321\n",
            "Loss: 3.4625113010406494\n",
            "Percent: 3.179250094383987\n",
            "Loss: 2.3995935916900635\n",
            "Percent: 3.3117188483166533\n",
            "Loss: 1.5141338109970093\n",
            "Percent: 3.444187602249319\n",
            "Loss: 5.5799336433410645\n",
            "Percent: 3.5766563561819855\n",
            "Loss: 2.6894819736480713\n",
            "Percent: 3.709125110114652\n",
            "Loss: 4.913868427276611\n",
            "Percent: 3.8415938640473177\n",
            "Loss: 1.9635028839111328\n",
            "Percent: 3.9740626179799845\n",
            "Loss: 2.845273971557617\n",
            "Percent: 4.10653137191265\n",
            "Loss: 3.8094358444213867\n",
            "Percent: 4.239000125845316\n",
            "Loss: 6.215887546539307\n",
            "Percent: 4.371468879777982\n",
            "Loss: 3.9003002643585205\n",
            "Percent: 4.503937633710649\n",
            "Loss: 2.8256423473358154\n",
            "Percent: 4.636406387643315\n",
            "Loss: 0.02382369339466095\n",
            "Percent: 4.768875141575981\n",
            "Loss: 3.862269163131714\n",
            "Percent: 4.901343895508647\n",
            "Loss: 5.675449371337891\n",
            "Percent: 5.033812649441313\n",
            "Loss: 2.3782546520233154\n",
            "Percent: 5.166281403373979\n",
            "Loss: 8.152100563049316\n",
            "Percent: 5.298750157306645\n",
            "Loss: 2.7319536209106445\n",
            "Percent: 5.431218911239311\n",
            "Loss: 0.01508046593517065\n",
            "Percent: 5.563687665171978\n",
            "Loss: 2.323242425918579\n",
            "Percent: 5.696156419104644\n",
            "Loss: 3.361112594604492\n",
            "Percent: 5.8286251730373095\n",
            "Loss: 2.7972090244293213\n",
            "Percent: 5.961093926969975\n",
            "Loss: 2.4317433834075928\n",
            "Percent: 6.093562680902642\n",
            "Loss: 4.907952308654785\n",
            "Percent: 6.226031434835308\n",
            "Loss: 2.643057107925415\n",
            "Percent: 6.358500188767974\n",
            "Loss: 3.3223559856414795\n",
            "Percent: 6.490968942700641\n",
            "Loss: 2.2586886882781982\n",
            "Percent: 6.623437696633307\n",
            "Loss: 3.645278215408325\n",
            "Percent: 6.7559064505659725\n",
            "Loss: 3.3942718505859375\n",
            "Percent: 6.888375204498638\n",
            "Loss: 3.861323595046997\n",
            "Percent: 7.020843958431305\n",
            "Loss: 5.065720081329346\n",
            "Percent: 7.153312712363971\n",
            "Loss: 1.8027812242507935\n",
            "Percent: 7.285781466296637\n",
            "Loss: 1.7297292947769165\n",
            "Percent: 7.418250220229304\n",
            "Loss: 0.4652928411960602\n",
            "Percent: 7.55071897416197\n",
            "Loss: 2.9509694576263428\n",
            "Percent: 7.6831877280946355\n",
            "Loss: 3.122192144393921\n",
            "Percent: 7.815656482027301\n",
            "Loss: 2.5429818630218506\n",
            "Percent: 7.948125235959969\n",
            "Loss: 3.032258987426758\n",
            "Percent: 8.080593989892634\n",
            "Loss: 2.327512741088867\n",
            "Percent: 8.2130627438253\n",
            "Loss: 2.4209964275360107\n",
            "Percent: 8.345531497757966\n",
            "Loss: 2.4761414527893066\n",
            "Percent: 8.478000251690633\n",
            "Loss: 7.046916961669922\n",
            "Percent: 8.6104690056233\n",
            "Loss: 2.8249351978302\n",
            "Percent: 8.742937759555964\n",
            "Loss: 3.159907102584839\n",
            "Percent: 8.875406513488631\n",
            "Loss: 3.211196184158325\n",
            "Percent: 9.007875267421298\n",
            "Loss: 5.572183132171631\n",
            "Percent: 9.140344021353963\n",
            "Loss: 3.7635366916656494\n",
            "Percent: 9.27281277528663\n",
            "Loss: 3.679274797439575\n",
            "Percent: 9.405281529219295\n",
            "Loss: 3.63041090965271\n",
            "Percent: 9.537750283151961\n",
            "Loss: 3.8432655334472656\n",
            "Percent: 9.670219037084628\n",
            "Loss: 1.7878469228744507\n",
            "Percent: 9.802687791017293\n",
            "Loss: 1.1747441291809082\n",
            "Percent: 9.93515654494996\n",
            "Loss: 2.9422523975372314\n",
            "Percent: 10.067625298882627\n",
            "Loss: 4.130038738250732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-56514c74441a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFmbZV5ACxeo",
        "outputId": "fa30fbb2-519e-4c5c-cd86-f446c11b3c18"
      },
      "source": [
        "filename = 'AA_LM_v1.pt'\n",
        "file_dir = Path('/content/content/MyDrive/' + filename)\n",
        "file_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/content/MyDrive/AA_LM_v1.pt')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dPEOnY6C5R9"
      },
      "source": [
        "torch.save(model, file_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1lA1tMTiyNw"
      },
      "source": [
        "## Weightdropout (voor later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nCPcZDGi1CP"
      },
      "source": [
        "class WeightDropout(torch.nn.Module):\n",
        "    \"Apply dropout to LSTM's hidden-hidden weights\"\n",
        "    \n",
        "    def __init__(self, module, weight_p):\n",
        "        super(WeightDropout, self).__init__()\n",
        "        self.module = module\n",
        "        self.weight_p = weight_p\n",
        "        \n",
        "        # Save the name of the layer weights in a list\n",
        "        num_layers = module.num_layers\n",
        "        layer_base_name = 'weight_hh_l'      \n",
        "        self.layer_weights = [layer_base_name + str(i) for i in range(num_layers)]\n",
        "        \n",
        "        # Make a copy of the weights in weightname_raw\n",
        "        for weight in self.layer_weights:\n",
        "            w = getattr(self.module, weight)\n",
        "            del module._parameters[weight]\n",
        "            self.module.register_parameter(f'{weight}_raw', torch.nn.Parameter(w))\n",
        "            \n",
        "        def _setweights(self):\n",
        "            \"Apply dropout to the raw weights\"\n",
        "            for weight in self.layer_weights:\n",
        "                raw_w = getattr(self, f'{weight}_raw')\n",
        "                if self.training:\n",
        "                    w = torch.nn.F(raw_w, p=self.weight_p)\n",
        "                else:\n",
        "                    w = raw_w.clone()\n",
        "                setattr(self.module, weight, w)\n",
        "                \n",
        "        def forward(self, *args):\n",
        "            self._setweights()\n",
        "            return self.module(*args)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}